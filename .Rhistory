boxplot(residuals(cars.lm))
qqnorm(residuals(cars.lm))
qqline(residuals(cars.lm))
par(mfrow=c(1,1))
plot(cars.lm)
# install.packages("lmtest")
library(lmtest)
dwtest(cars.lm, alternative = "two.sided")
cars[23,]
dim(cars)
cars[-23,]
dim(cars[-23,])
shapiro.test(residuals(cars.lm))
library(lmtest)
bptest(cars.lm)
data("trees")
head(trees)
hist(trees$Volume)
hist(trees$Volume^2)
library(MASS)
?boxcox
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
bctrans
which(bctrans$y==max(bctrans$y))
bctrans$x[62]
hist(trees$Volume)
hist(trees$Volume^0.31)
# ?cars
summary(cars)
cars.lm <- lm(dist ~ speed, data = cars)
names(cars.lm)
coef(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
summary(cars.lm)
-17.58 + 3.93 * (8) # point estimate
cars[5,] # real data
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
carsumry$sigma
summary(cars.lm)
-17.58 + 3.93 * (8) # point estimate
cars[5,] # real data
fitted(cars.lm)
head(cars)
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
data.frame(speed = c(6,8,21))
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=15)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=12)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
summary(cars.lm)
carsumry$sigma
summary(cars.lm)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
carsumry$sigma
summary(cars.lm)
confint(cars.lm)
# new <- data.frame(speed = c(5,6,21))
# predict(cars.lm, newdata = new, interval = "confidence")
# predict(cars.lm, newdata = new, interval = "prediction")
library(HH)
ci.plot(cars.lm)
# or
# library(UsingR)
# simple.lm(cars$speed, cars$dist, show.ci=TRUE)
x = c(18, 23, 25, 35, 65, 54, 34, 56, 72, 19, 23, 42, 18, 39, 37)
y = c(202, 186, 187, 180, 156, 169, 174, 172, 153, 199, 193, 174, 198, 183, 178)
plot(x,y) # make a plot
lm(y ~ x)
lm.result = lm(y ~ x)
summary(lm.result)
plot(x,y) # make a plot
abline(lm(y ~ x)) # plot the regression line
plot(x,y) # make a plot
abline(coef(lm.result))
summary(lm.result)
plot(x,y) # make a plot
plot(x,y, xlim=c(0,80)) # make a plot
abline(coef(lm.result)) #lm(y ~ x)) # plot the regression lin
plot(x,y, xlim=c(0,80), ylim=c(150,240)) # make a plot
abline(coef(lm.result)) #lm(y ~ x)) # pl
summary(lm.result)
t = (b1-(0))/SE
b1 = -0.79773
SE = 0.06996
t = (b1-(0))/SE
t
t = (b1-(-1))/SE # (obs. value - hyp.value)/SE
t
pt(t, 13, lower.tail = FALSE)
# multiply by 2 for a two-sided test
pt(t, 13, lower.tail = FALSE)*2 # < 0.05, REJECT H0: it is unlikely that for this data
# COMMENTED LINES - CALCULATIONS BY HAND, YOU CAN SKIP THEM AND USE THE OUTPUT OF THE REGRESSION ANALYSIS
# SE.b0 = s*(sqrt((1/n)+(mean(x)^2/sum((x-mean(x))^2)))) # formula for the standard error of the intercept
SE.b0 = 2.86694
b0 = coef(lm.result)[[1]]
coef(lm.result)[[1]]
t = (b0 - 220)/SE.b0
t
pt(t, 13, lower.tail = TRUE) # FIND THE LEFT TAIL FOR THIS VALUE OF t AND 15-2 df
pt(t, 13, lower.tail = FALSE)*2 # TWO TAILED TEST
growth = c(12, 10, 8, 11, 6, 7, 2, 3.5, 3.5)
tannin = 0:8
tannin
plot(growth ~ tannin)
plot(tannin ~ growth)
plot(growth ~ tannin)
plot(tannin, growth)
lm(growth ~ tannin)
lm.result <- lm(growth ~ tannin)
summary(lm.result)
plot(growth ~ tannin)
abline(coef(lm.result))
abline(coef(lm.result), lwd=2)
lm.result <- lm(growth ~ tannin)
summary(lm.result)
plot(growth ~ tannin)
abline(coef(lm.result), lwd=2)
abline(coef(lm.result), lwd=2, col="red")
lm.result <- lm(growth ~ tannin)
summary(lm.result)
plot(growth ~ tannin)
abline(coef(lm.result), lwd=2, col="red")
t = (-1.1583 - (-1.5))/0.2236
t
dim(cars)
dim(x)
length(x)
t = (-1.1583 - (-1.5))/0.2236
pt(t, 7, lower.tail = FALSE)
confint(lm.result)
data(cars)
cars.lm <- lm(dist ~ speed, data = cars)
coef(cars.lm)
names(cars.lm)
residuals(cars.lm)
par(mfrow=c(1,3))
hist(residuals(cars.lm))
boxplot(residuals(cars.lm))
qqnorm(residuals(cars.lm))
qqline(residuals(cars.lm))
par(mfrow=c(1,1))
plot(cars.lm)
# install.packages("lmtest")
library(lmtest)
dwtest(cars.lm, alternative = "two.sided")
shapiro.test(residuals(cars.lm))
library(lmtest)
bptest(cars.lm)
data("trees")
head(trees)
hist(trees$Volume)
hist(trees$Volume^2)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
bctrans
which(bctrans$y==max(bctrans$y))
bctrans$x[58]
which(bctrans$x==max(bctrans$y))
which(bctrans$y==max(bctrans$y))
bctrans$x[max(bctrans$y)]
which(bctrans$y==max(bctrans$y))
bctrans$x[58]
which(bctrans$y==max(bctrans$y))
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
which(bctrans$y==max(bctrans$y))
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
seq(0, 0.5, length = 10)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
which(bctrans$y==max(bctrans$y))
bctrans
bctrans$x[62]
hist(trees$Volume)
hist(trees$Volume^0.31)
bctrans
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
max(bctrans$y)
bctrans$y
head(data.frame(bctrans$y, bctrans$x))
library(dplyr)
risultati.bc <- data.frame(bctrans$y, bctrans$x)
head(risultati.bc)
arrange(risultati.bc, bctrans.y)
head(risultati.bc)
View(risultati.bc)
View(risultati.bc)
# using the read.csv function
y <- read.csv("data/captures.csv",sep=";")
View(y)
class(y) # this is a data frame
head(y) # we can see the first rows of our data frame
# or from an excel file:
# we need a specific package in this case, and we need to install it:
# install.packages("xlsx") # the line is commented because you just need to run it once
library(xlsx)
## ---- Extract a column (i.e. a variable) -----
# we can do this using '$'
y$weight_g
# or subsetting the data frame, using square brackets '[ ]'
y["weight_g"]
# Let's ask R what kind of variable we are dealing with, using the 'class' function again
class(y$weight_g)
y[,10]
w <- y$weight_g
w
hist(y$weight_g, main="", xlab="Animal weigth (g)") # with default break
hist(y$weight_g, main="", xlab="Animal weigth (g)") # with default break
hist(y$weight_g, breaks=30, main="", xlab="Animal weigth (g)") # we specified a single number giving
stripchart(y$weight_g, xlab="Animal weigth (g)")
stripchart(y$weight_g, xlab="Animal weigth (g)", method="jitter")
stripchart(y$weight_g, xlab="Animal weigth (g)", method="stack")
# boxplot
boxplot(y$weight_g, ylab="Animal weigth (g)")
boxplot(y$weight_g ~ y$sex + y$age, ylab="Animal weigth (g)")
# exercise (by your own): do the same with the foot lenght
boxplot(y$footlength_mm, ylab="Foot length (mm)")
## the mean and the median
weight <- na.omit(y$weight_g)
weight
# mean
mean(weight)
mean(y$weight_g)
# median
median(weight)
hist(weight,prob=T,ylim=c(0,0.05)) # prob=T for relative frequencies (density)
hist(weight,prob=T,ylim=c(0,0.05)) # prob=T for relative frequencies (density)
lines(density(rnorm(1000000,mean(weight),sd(weight))),col="red")
segments(mean(weight),0,mean(weight),0.047,col="blue")
segments(median(weight),0,median(weight),0.047,col="green")
## the mode
# R does not have a standard in-built function to calculate mode.
# So we create a user function to calculate mode of a data set in R.
# This function takes the vector as input and gives the mode value as output.
# Create the function.
getmode <- function(x) {
uniqv <- unique(x)
uniqv[which.max(tabulate(match(x, uniqv)))]
}
getmode(weight)
## range
range(weight)
## quantile
quantile(weight) # in R, quartiles are the default for the quantile function
boxplot(weight, range=0)
boxplot(na.omit(y$footlength_mm))
boxplot(na.omit(y$footlength_mm), range=0)
# summary
summary(weight)
## variance
var(weight)
## standard deviation
sd(weight)
length(weight)
sd(weight)/sqrt(119)
sample(x = 1:6, size = 5, replace = FALSE)
x = 1:6
x
sample(x = 1:6, size = 5, replace = FALSE)
sample(x = 1:6, size = 20, replace = TRUE)
sample(x = 1:6, size = 20, replace = TRUE) # you get different numbers
sample(x = 1:6, size = 20, replace = TRUE) # again
RollDie <- function(n) sample(1:6, n, replace = TRUE)
d1 <- RollDie(n = 50)
d1
(d1 == 6)
sum(d1 == 6)
sum(d1 == 6)/50
RollDie <- function(n) sample(1:6, n, replace = TRUE)
d1 <- RollDie(n = 50)
sum(d1 == 6)
sum(d1 == 6)/50
hist(d1, probability = TRUE, breaks = seq(0.5,6.5,1))
hist(d1)
hist(d1)
hist(d1, probability = TRUE, breaks = seq(0.5,6.5,1))
sims <- vector("list", 500)
probs <- vector("numeric", 500)
for (n in 1:500) {
sims[[n]] <- RollDie(n)
probs[n] <- sum(sims[[n]] == 6)/n
}
plot(probs)
abline(h=1/6)
sims <- vector("list", 500)
sims
sims[[500]] <- RollDie(n = 50)
sims <- vector("list", 500)
sims[[500]] <- RollDie(n = 50)
sims
probs <- vector("numeric", 500)
probs
sims <- vector("list", 500)
probs <- vector("numeric", 500)
for (n in 1:500) {
sims[[n]] <- RollDie(n)
probs[n] <- sum(sims[[n]] == 6)/n
}
sims
sims[[1]]
sims[[2]]
sims[[500]]
probs
sims <- vector("list", 500)
probs <- vector("numeric", 500)
for (n in 1:500) {
sims[[n]] <- RollDie(n)
probs[n] <- sum(sims[[n]] == 6)/n
}
plot(probs)
abline(h=1/6)
plot(probs)
plot(probs)
abline(h=1/6)
sample(x=c("testa","croce"), size = 5, replace = TRUE)
sample(1:6, size = 1, replace = TRUE)
sample(1:6, size = 1, replace = TRUE)
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
roll1
for (i in 1:100) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
roll1
(roll1 == roll2)
# We can ask how many doubles we came up with:
sum(roll1 == roll2)
sum(roll1 == roll2)/100
roll1 <- vector("list", 500)
roll2 <- vector("list", 500)
roll1 <- vector("list", 500)
roll2 <- vector("list", 500)
probs <- vector("numeric", 500)
for (n in 1:500) {
roll1[[n]] <- RollDie(n)
roll2[[n]] <- RollDie(n)
probs[n] <- sum(roll1[[n]] == roll2[[n]])/n
}
plot(probs)
abline(h=1/6)
n = 500
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
hist((roll1 + roll2), density = 100, breaks = 1:12, prob = T)
barplot(table(roll1 + roll2), main = "2 Dice Sum, 100 Rolls")  #this works better for this case
rolls <- roll1 + roll2
rolls
sum(rolls == 7)
sum(rolls == 7)/n
n = 1500
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
# We can ask how many times this happen:
sum(roll1 == 6 & roll2 == 6)
# the relative frequency is:
sum(roll1 == 6 & roll2 == 6)/n
(1/6)*(1/6)
n = 50
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
# We can ask how many times this happen:
sum(roll1 == 6 & roll2 == 6)
# the relative frequency is:
sum(roll1 == 6 & roll2 == 6)/n
n = 100
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
# We can ask how many times this happen:
sum(roll1 == 6 & roll2 == 6)
# the relative frequency is:
sum(roll1 == 6 & roll2 == 6)/n
n = 1500
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
# We can ask how many times this happen:
sum(roll1 == 6 & roll2 == 6)
# the relative frequency is:
sum(roll1 == 6 & roll2 == 6)/n
y <- read.csv("data/captures.csv",sep=";")
y <- na.omit(y[,c("age", "sex")])
View(y)
y %>%
group_by(age) %>%
summarise(n = n())
library(dplyr)
y %>%
group_by(age) %>%
summarise(n = n())
y %>%
group_by(age) %>%
summarise(n = n()) %>%
# ungroup() %>%
mutate(prop = n/sum(n))
y %>%
group_by(age) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
79+14
79/93
y %>%
group_by(age) %>%
summarise(n = n())
library(dplyr)
age.marginal.df <-
y %>%
group_by(age) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
age.marginal.df
sex.marginal.df <-
y %>%
group_by(sex) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
sex.marginal.df
joint.df <-
y %>%
group_by(age, sex) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
joint.df
joint.prob <-
joint.df %>%
filter(age == "A", sex == "F") %>%
.$prop
joint.prob
cond.prob
cond.prob <- joint.prob/marg.prob
marg.prob <-
age.marginal.df %>%
filter(age == "A") %>%
.$prop
marg.prob
cond.prob <- joint.prob/marg.prob
cond.prob
0.4050633 * 0.8494624
