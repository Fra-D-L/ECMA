# After an orthogonal rotation (such as varimax), the "rotated-principal" axes are not orthogonal, and orthogonal projections on them do not make sense. So one should rather drop this whole axes/projections point of view. It would be weird to still call it PCA (which is all about projections with maximal variance etc.).
# Extract the results for variables
var <- get_pca_var(res.pca)
var
# Contribution of variables
var$contrib
colSums(var$contrib)
# correlation of variables with the first 4 PC
res.pca$var$cor[, 1:4]
# axis characterization
dimdesc(res.pca)
# Graph of variables: default plot
fviz_pca_var(res.pca, col.var = "steelblue")
# Itâ€™s possible to control variable colors using their contributions to the principal axes:
# Control variable colors using their contributions
# Use gradient color
fviz_pca_var(res.pca, col.var="contrib")+
scale_color_gradient2(low="white", mid="blue",
high="red", midpoint = 25) +
theme_minimal()
# Variable contributions on axis 1
fviz_contrib(res.pca, choice="var", axes = 1 )+
labs(title = "Contributions to Dim 1")
# Variable contributions on axis 2
fviz_contrib(res.pca, choice="var", axes = 2 )+
labs(title = "Contributions to Dim 2")
# Variable contributions on axes 1 + 2
fviz_contrib(res.pca, choice="var", axes = 1:2)+
labs(title = "Contributions to Dim 1+2")
# Extract the results for individuals
ind <- get_pca_ind(res.pca)
ind
# Coordinates of individuals
head(ind$coord)
# compare to:
head(res.prcomp$x)
# Graph of individuals
# 1. Use repel = TRUE to avoid overplotting
fviz_pca_ind(res.pca, repel = TRUE)+
theme_minimal()
# Color by groups: habillage=iris$Species
# Show points only: geom = "point"
p <- fviz_pca_ind(res.pca, geom = "point",
habillage=iris$Species, addEllipses=TRUE,
ellipse.level= 0.95)+ theme_minimal()
print(p)
# Change group colors manually
# Read more: http://www.sthda.com/english/wiki/ggplot2-colors
p + scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
theme_minimal()
fviz_pca_ind(res.pca, repel = TRUE)+
theme_minimal()
# Extract the results for individuals
ind <- get_pca_ind(res.pca)
ind
# Coordinates of individuals
head(ind$coord)
# compare to:
head(res.prcomp$x)
# Graph of individuals
# 1. Use repel = TRUE to avoid overplotting
fviz_pca_ind(res.pca, repel = TRUE)+
theme_minimal()
# Color by groups: habillage=iris$Species
# Show points only: geom = "point"
p <- fviz_pca_ind(res.pca, geom = "point",
habillage=iris$Species, addEllipses=TRUE,
ellipse.level= 0.95)+ theme_minimal()
print(p)
# Change group colors manually
# Read more: http://www.sthda.com/english/wiki/ggplot2-colors
p + scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
theme_minimal()
colorvar<-col="red"
colorvar->col="red"
colorvar<-col="red"
# Color by groups: habillage=iris$Species
# Show points only: geom = "point"
p <- fviz_pca_ind(res.pca, geom = "point",
habillage=iris$Species, addEllipses=TRUE,
ellipse.level= 0.95)+ theme_minimal()
# Extract the results for individuals
ind <- get_pca_ind(res.pca)
ind
# Coordinates of individuals
head(ind$coord)
# compare to:
head(res.prcomp$x)
# Graph of individuals
# 1. Use repel = TRUE to avoid overplotting
fviz_pca_ind(res.pca, repel = TRUE)+
theme_minimal()
# Color by groups: habillage=iris$Species
# Show points only: geom = "point"
p <- fviz_pca_ind(res.pca, geom = "point",
habillage=iris$Species, addEllipses=TRUE,
ellipse.level= 0.95)+ theme_minimal()
print(p)
# Change group colors manually
# Read more: http://www.sthda.com/english/wiki/ggplot2-colors
p + scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
theme_minimal()
# Biplot of individuals and variables
# ++++++++++++++++++++++++++
# Only variables are labelled
fviz_pca_biplot(res.pca,  label="var", habillage=iris$Species,
addEllipses=TRUE, ellipse.level=0.95) +
theme_minimal()
# # df <- USArrests[,1:2]
# df_birds <- read_xlsx("data/short.xlsx", col_types = c("text","numeric","numeric"))
# df <- na.omit(df_birds)
# df <- scale(df[,2:3])
# head(df)
european_birds <- read_delim("data/european_birds.txt",
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
fviz_nbclust(df, kmeans, method = "wss")
---
title: "K-means clustering - step by step"
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering algorithms & visualization
library(FactoMineR)
library(readxl)
library(readr)
# # df <- USArrests[,1:2]
# df_birds <- read_xlsx("data/short.xlsx", col_types = c("text","numeric","numeric"))
# df <- na.omit(df_birds)
# df <- scale(df[,2:3])
# head(df)
european_birds <- read_delim("data/european_birds.txt",
delim = "\t", escape_double = FALSE,
trim_ws = TRUE)
european_birds %>%
dplyr::select(Species,
LengthU_MEAN,
# WingU_MEAN,
Clutch_MEAN,
`Life span`) -> df_birds
df_birds <- na.omit(df_birds)
df <- scale(df_birds[,2:dim(df_birds)[2]])
head(df)
distance <- get_dist(df)
fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
fviz_nbclust(df, kmeans, method = "wss")
fviz_nbclust(df, kmeans, method = "silhouette")
gap_stat <- clusGap(df, FUN = kmeans, nstart = 25,
K.max = 10, B = 50)
fviz_gap_stat(gap_stat)
# Compute k-means clustering with k = 4
set.seed(123)
final <- kmeans(df, 3, nstart = 25)
print(final)
fviz_cluster(final, data = df,
geom = c("point"),
ellipse.type = "euclid")
final$cluster
df_birds %>%
mutate(cluster_id = final$cluster) -> df_birds_cluster
write.csv(df_birds_cluster, file = "output/df_birds_cluster.csv")
writexl::write_xlsx(df_birds_cluster, "output/df_birds_cluster.xlsx")
head(df_birds_cluster)
sample(x = 1:6, size = 5, replace = FALSE)
sample(x = 1:6, size = 20, replace = TRUE)
sample(x = 1:6, size = 20, replace = TRUE) # you get different numbers
sample(x = 1:6, size = 20, replace = TRUE) # again
RollDie <- function(n) sample(1:6, n, replace = TRUE)
d1 <- RollDie(n = 50)
sum(d1 == 6)
sum(d1 == 6)/50
hist(d1)
hist(d1, probability = TRUE, breaks = seq(0.5,6.5,1))
sims <- vector("list", 500)
probs <- vector("numeric", 500)
for (n in 1:500) {
sims[[n]] <- RollDie(n)
probs[n] <- sum(sims[[n]] == 6)/n
}
plot(probs)
abline(h=1/6)
sample(x=c("testa","croce"), size = 5, replace = TRUE)
sample(1:6, size = 1, replace = TRUE)
sample(1:6, size = 1, replace = TRUE)
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:100) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
# We can ask how many doubles we came up with:
sum(roll1 == roll2)
# relative frequency
sum(roll1 == roll2)/100
roll1 <- vector("list", 500)
roll2 <- vector("list", 500)
probs <- vector("numeric", 500)
for (n in 1:500) {
roll1[[n]] <- RollDie(n)
roll2[[n]] <- RollDie(n)
probs[n] <- sum(roll1[[n]] == roll2[[n]])/n
}
plot(probs)
abline(h=1/6)
n = 500
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
hist((roll1 + roll2), density = 100, breaks = 1:12, prob = T)
barplot(table(roll1 + roll2), main = "2 Dice Sum, 100 Rolls")  #this works better for this case
rolls <- roll1 + roll2
sum(rolls == 7)
sum(rolls == 7)/n
n = 1500
roll1 = NULL  #This initializes our variable - i.e. it creates a spot in memory for it. We need to do this for any vector, table, matrix, dataframe, but not for single numbers
roll2 = NULL
for (i in 1:n) {
roll1[i] = RollDie(1)
roll2[i] = RollDie(1)
}
# We can ask how many times this happen:
sum(roll1 == 6 & roll2 == 6)
# the relative frequency is:
sum(roll1 == 6 & roll2 == 6)/n
(1/6)*(1/6)
0.02777778+0.02777778+0.02777778+0.02777778+0.02777778+0.02777778
# or
0.02777778*6
y <- read.csv("data/captures.csv",sep=";")
y <- na.omit(y[,c("age", "sex")]); y
library(dplyr)
age.marginal.df <-
y %>%
group_by(age) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
age.marginal.df
sex.marginal.df <-
y %>%
group_by(sex) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
sex.marginal.df
joint.df <-
y %>%
group_by(age, sex) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
joint.df
joint.prob <-
joint.df %>%
filter(age == "A", sex == "F") %>%
.$prop
joint.prob
marg.prob <-
age.marginal.df %>%
filter(age == "A") %>%
.$prop
marg.prob
cond.prob <- joint.prob/marg.prob
cond.prob
library(Rmisc)
library(Hmisc)
library(ggplot2)
library(boot)
dati <- read.csv("data/captures.csv", sep=";")
CI(dati$weight_g, ci=0.95)
CI(na.omit(dati$weight_g), ci=0.95)
dati2 <- na.omit(dati)
group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli <- group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli
ggplot(intervalli, aes(x=sex, y=weight_g.mean, colour=sex)) +
geom_errorbar(aes(ymin=weight_g.lower, ymax=weight_g.upper), width=.1) +
geom_line() +
geom_point()
as.data.frame(CI(na.omit(dati$weight_g), ci=0.95)) -> CImean
CImean
variabile <- dati2$footlength_mm # o qualsiasi altra variabile numerica
# script 'generalizzato'
intervalli <- group.CI(variabile ~ sex,
data= dati2,
ci=0.95)
intervalli
ggplot(intervalli, aes(x=sex, y=variabile.mean, colour=sex)) +
geom_errorbar(aes(ymin=variabile.lower, ymax=variabile.upper), width=.1) +
geom_line() +
geom_point()
boot.data <- boot(dati2$weight_g,
function(x,i) mean(x[i]),
R=10000)
boot.ci(boot.data,
conf = 0.95)
x <- c(15, 10, 13, 7, 9, 8, 21, 9, 14, 8)
y <- c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
shapiro.test(c(8, 6))
shapiro.test(c(8, 6, 9))
shapiro.test(c(9, 9, 9))
shapiro.test(c(9, 9, 9,1))
shapiro.test(c(9, 9, 9.1))
shapiro.test(c(0, 0, 9999999999999))
shapiro.test(c(2, 7, 7, 9))
shapiro.test(c(2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9))
# homogeneity of variances
var(x)/var(y)
var.test(x,y)
95/95
var(x); var(y); var(x)/var(y)
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
smart_ttest <- function(x, y, alpha = 0.05, ...) {
# Test delle varianze
var_result <- var.test(x, y)
# Decide quale t-test usare
if (var_result$p.value > alpha) {
cat("Varianze uguali (p =", round(var_result$p.value, 4), ") â†’ Student t-test\n")
t.test(x, y, var.equal = TRUE, ...)
} else {
cat("Varianze diverse (p =", round(var_result$p.value, 4), ") â†’ Welch t-test\n")
t.test(x, y, var.equal = FALSE, ...)
}
}
smart_ttest(x, y)
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
smart_ttest(x, y)
# non parametric test
wilcox.test(x,y,
paired = FALSE,
alternative = "two.sided")
z.test <- function(x, sigma) {}
View(z.test)
View(RollDie)
function(n) sample(1:6, n, replace = TRUE)
RollDie()
RollDie(9)
View(RollDie)
cat("Z test\nZ = ", Z, "\n")
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
cat("Z test\nZ = ", Z, "\n")
cat("p-value =", p_val, "\n")
}
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform an accurate Z test")
}
cat("Z test\nZ = ", Z, "\n")
cat("p-value =", p_val, "\n")
}
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform a Z test")
}
cat("Z test\nZ = ", Z, "\n")
cat("p-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 005, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105, 105, 105, 105, 105, 105, 105),
sigma=15,
mu=100
)
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform a Z test")
}
cat("Z test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 005, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105, 105, 105, 105, 105, 105, 105),
sigma=15,
mu=100
)
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 5, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105),
sigma=15,
mu=100
)
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform a Z test\n")
}
cat("Z test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform an accurate Z test\n")
}
cat("Z test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 5, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105),
sigma=15,
mu=100
)
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform an accurate Z test\n(n should be â‰¥ 30")
}
cat("Z test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 5, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105),
sigma=15,
mu=100
)
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform an accurate Z test (n should be â‰¥ 30)\n")
}
cat("Z test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 5, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105),
sigma=15,
mu=100
)
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform an accurate Z test (n is < 30)\n")
}
cat("Z test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 5, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105),
sigma=15,
mu=100
)
z.test <- function(x, sigma, mu = 0) {
n <- length(x)
xbar <- mean(x)
Z <- (xbar - mu) / (sigma / sqrt(n))
p_val <- 2 * (1 - pnorm(abs(Z)))
if (n < 30) {
cat("Warning!\nA sample size of ", n, " is too small to perform an accurate Z test (n is < 30)\n")
}
cat("Z-test\nZ = ", Z, "\tp-value =", p_val, "\n")
}
z.test(
c(105, 105, 105, 107, 103, 110, 100, 205, 5, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105,
105, 105, 105, 105, 105, 115, 95, 105),
sigma=15,
mu=100
)
