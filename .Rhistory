summarise(n = n())
library(dplyr)
age.marginal.df <-
y %>%
group_by(age) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
age.marginal.df
sex.marginal.df <-
y %>%
group_by(sex) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
sex.marginal.df
joint.df <-
y %>%
group_by(age, sex) %>%
summarise(n = n()) %>%
ungroup() %>%
mutate(prop = n/sum(n))
joint.df
joint.prob <-
joint.df %>%
filter(age == "A", sex == "F") %>%
.$prop
joint.prob
cond.prob
cond.prob <- joint.prob/marg.prob
marg.prob <-
age.marginal.df %>%
filter(age == "A") %>%
.$prop
marg.prob
cond.prob <- joint.prob/marg.prob
cond.prob
0.4050633 * 0.8494624
library(Rmisc)
library(Hmisc)
library(ggplot2)
library(boot)
dati <- read.csv("data/captures.csv", sep=";")
library(Rmisc)
library(Hmisc)
library(ggplot2)
library(boot)
dati <- read.csv("data/captures.csv", sep=";")
dati <- read.csv("data/captures.csv", sep=";")
CI(dati$weight_g, ci=0.95)
CI(na.omit(dati$weight_g), ci=0.95)
dati2 <- na.omit(dati)
group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
dati2 <- na.omit(dati)
group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli <- group.CI(weight_g ~ sex,
data= dati2,
ci=0.95)
intervalli
ggplot(intervalli, aes(x=sex, y=weight_g.mean, colour=sex)) +
#geom_errorbar(aes(ymin=weight_g.lower, ymax=weight_g.upper), width=.1) +
#geom_line() +
geom_point()
ggplot(intervalli, aes(x=sex, y=weight_g.mean, colour=sex)) +
geom_errorbar(aes(ymin=weight_g.lower, ymax=weight_g.upper), width=.1) +
geom_line() +
geom_point()
head(dati2)
as.data.frame(CI(na.omit(dati$weight_g), ci=0.95)) -> CImean
CImean
boot.data <- boot(dati2$weight_g,
function(x,i) mean(x[i]),
R=10000)
boot.data
boot.ci(boot.data,
conf = 0.95)
library(dplyr)
captures <- read.csv("data/captures.csv", sep=";")
captures %>%
filter(age=="A") -> adults
head(adults)
adults %>%
group_by(animal_id, sex) -> grouped
grouped %>%
arrange(animal_id)
grouped %>%
summarise(count=n(), individual.weight = mean(weight_g, na.rm = TRUE)) -> ind.w
ind.w
#?qqplot
qqnorm(ind.w$individual.weight); qqline(ind.w$individual.weight, col="red")
qqnorm(ind.w$individual.weight)
#?qqplot
qqnorm(ind.w$individual.weight); qqline(ind.w$individual.weight, col="red")
shapiro.test(ind.w$individual.weight)
t.test(ind.w$individual.weight, mu = 30)
length(ind.w$individual.weight)
ind.w$individual.weight
length(na.omit(ind.w$individual.weight))
## is the weight of females and males different?
# we use again the summarise dplyr function
ind.w %>%
group_by(sex) %>%
summarise(count=n(), class.weight = mean(individual.weight, na.rm = TRUE))
# again, if you could not install dplyr, use the following code
# tapply(ind.w$individual.weight, ind.w$sex, mean, na.rm = TRUE)
# We can see the difference in weight that we observe between males and females
w.f <- (subset(ind.w, sex=="F"))$individual.weight
w.m <- (subset(ind.w, sex=="M"))$individual.weight
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.m); qqline(w.m, col="red")
shapiro.test(w.f)
shapiro.test(w.m)
x <- rnorm(100,0,1)
curve(df(x, df1=1, df2=1), from=0, to=5, lty=1, ylim=c(0,2))
curve(df(x, df1=2, df2=1), from=0, to=5, lty=2, add=T)
curve(df(x, df1=5, df2=2), from=0, to=5, lty=3, add=T)
curve(df(x, df1=100, df2=1), from=0, to=5, lty=4, add=T)
curve(df(x, df1=100, df2=100), from=0, to=5, lty=5, add=T)
var(w.f, na.rm = T)
var(w.m, na.rm = T)
var(w.f, na.rm = T)/var(w.m, na.rm = T)
var.test(w.f,w.m)
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
x <- c(15, 10, 13, 7, 9, 8, 21, 9, 14, 8)
y <- c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var(x)/var(y)
var.test(x,y)
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
# non parametric test
wilcox.test(x,y,
paired = FALSE,
alternative = "two.sided")
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var.test(x,y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
# ?t.test
t.test(w.f, w.m,
var.equal = TRUE,
paired = FALSE,
alternative = "two.sided") # greater/less
library(dplyr)
captures <- read.csv("data/captures.csv", sep=";")
captures %>%
filter(age=="A") -> adults
head(adults)
adults %>%
group_by(animal_id, sex) -> grouped
grouped %>%
arrange(animal_id)
grouped %>%
summarise(count=n(), individual.weight = mean(weight_g, na.rm = TRUE)) -> ind.w
ind.w
#?qqplot
qqnorm(ind.w$individual.weight); qqline(ind.w$individual.weight, col="red")
shapiro.test(ind.w$individual.weight)
t.test(ind.w$individual.weight, mu = 30)
length(na.omit(ind.w$individual.weight))
## is the weight of females and males different?
# we use again the summarise dplyr function
ind.w %>%
group_by(sex) %>%
summarise(count=n(), class.weight = mean(individual.weight, na.rm = TRUE))
# again, if you could not install dplyr, use the following code
# tapply(ind.w$individual.weight, ind.w$sex, mean, na.rm = TRUE)
# We can see the difference in weight that we observe between males and females
w.f <- (subset(ind.w, sex=="F"))$individual.weight
w.m <- (subset(ind.w, sex=="M"))$individual.weight
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.m); qqline(w.m, col="red")
shapiro.test(w.f)
shapiro.test(w.m)
x <- rnorm(100,0,1)
curve(df(x, df1=1, df2=1), from=0, to=5, lty=1, ylim=c(0,2))
curve(df(x, df1=2, df2=1), from=0, to=5, lty=2, add=T)
curve(df(x, df1=5, df2=2), from=0, to=5, lty=3, add=T)
curve(df(x, df1=100, df2=1), from=0, to=5, lty=4, add=T)
curve(df(x, df1=100, df2=100), from=0, to=5, lty=5, add=T)
var(w.f, na.rm = T)
var(w.m, na.rm = T)
var.test(w.f,w.m)
var(w.f, na.rm = T)/var(w.m, na.rm = T)
boxplot(ind.w$individual.weight ~ ind.w$sex)
# ?t.test
t.test(w.f, w.m,
var.equal = TRUE,
paired = FALSE,
alternative = "two.sided") # greater/less
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
x <- c(15, 10, 13, 7, 9, 8, 21, 9, 14, 8)
y <- c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var(x)/var(y)
var.test(x,y)
x
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
x <- c(15, 10, 13, 7, 9, 8, 21, 9, 14, 8)
y <- c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var(x)/var(y)
var.test(x,y)
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
# non parametric test
wilcox.test(x,y,
paired = FALSE,
alternative = "two.sided")
library(pwr)
install.packages("pwr")
library(pwr)
pwr.t.test(n=4, d = 0.25, sig.level = 0.05, type = "two.sample",
alternative = "less")
pwr.t.test(n=12, d = 0.25, sig.level = 0.05, type = "two.sample",
alternative = "less")
pwr.t.test(n=20, d = 0.25, sig.level = 0.05, type = "two.sample",
alternative = "less")
pwr.t.test(n=20, d = 0.25, sig.level = 0.05,
alternative = "less")
pwr.t.test(n=20, d = 0.25, sig.level = 0.05, type="paired",
alternative = "less")
pwr.t.test(n=25, d = 0.25, sig.level = 0.05, type="paired",
alternative = "less")
library(pwr)
pwr.t2n.test(n1 = 4, n2= 4, d = 0.25, sig.level = 0.05)
pwr.t2n.test(n1 = 6, n2= 6, d = 0.25, sig.level = 0.05)
pwr.t2n.test(n1 = 10, n2= 10, d = 0.25, sig.level = 0.05)
pwr.t2n.test(n1 = 20, n2= 20, d = 0.25, sig.level = 0.05)
pwr.t2n.test(n1 = 20, n2= 20, d = 0.5, sig.level = 0.05)
pwr.t2n.test(n1 = 40, n2= 40, d = 0.5, sig.level = 0.05)
8*4
pwr.t2n.test(n1 = 32, n2= 32, d = 0.5, sig.level = 0.05)
dati <- read.csv("data/sim_betadiv.csv")
View(dati)
dati <- read.csv("data/sim_betadiv.csv",sep=";")
View(dati)
dati <- read.csv("data/sim_betadiv.csv",sep=";",dec=",")
wilcox.test(betadiv ~ anno,
paired = TRUE,
alternative = "two.sided",
data = dati)
rnorm(n= 64, mean = 7, sd = 1)
bd <- rnorm(n= 64, mean = 7, sd = 1)
dati$betadiv <- bd
wilcox.test(betadiv ~ anno,
paired = TRUE,
alternative = "two.sided",
data = dati)
bd1 <- rnorm(n= 32, mean = 7, sd = 1)
bd2 <- rnorm(n= 32, mean = 20, sd = 5)
dati$betadiv <- c(bd1,bd2)
dati <- read.csv("data/sim_betadiv.csv",sep=";",dec=",")
bd1 <- rnorm(n= 32, mean = 7, sd = 1)
bd2 <- rnorm(n= 32, mean = 20, sd = 5)
dati$betadiv <- c(bd1,bd2)
wilcox.test(betadiv ~ anno,
paired = TRUE,
alternative = "two.sided",
data = dati)
dati <- read.csv("data/sim_betadiv.csv",sep=";",dec=",")
bd1 <- rnorm(n= 32, mean = 8, sd = 2)
bd2 <- rnorm(n= 32, mean = 7, sd = 1)
dati$betadiv <- c(bd1,bd2)
wilcox.test(betadiv ~ anno,
paired = TRUE,
alternative = "two.sided",
data = dati)
library(dplyr)
## chi2 - goodness of fit test
freq <- c(22, 21, 22, 27, 22, 36)
probs <- rep(1/6, 6)
chisq.test(freq, p = probs)
## chi2 - test of independence
yesbelt <- c(12813, 647, 359, 42)
nobelt <- c(65963, 4000, 2642, 303)
chisq.test(data.frame(yesbelt, nobelt))
names(chisq.test(data.frame(yesbelt, nobelt)))
data.frame(yesbelt, nobelt)
rowSums(data.frame(yesbelt, nobelt))
colSums(data.frame(yesbelt, nobelt))
# for the first cell
78776*13861/sum(data.frame(yesbelt, nobelt))
# for the whole dataframe
n = sum(data.frame(yesbelt, nobelt))
data.frame(yesbelt, nobelt) %>%
mutate(somma.riga = rowSums(data.frame(yesbelt, nobelt)),
e.yesbelt = somma.riga*sum(yesbelt)/n,
e.nobelt = somma.riga*sum(nobelt)/n)
# compare with the values calculated by R
chisq.test(data.frame(yesbelt, nobelt))$exp
data.frame(yesbelt, nobelt) %>%
mutate(somma.riga = rowSums(data.frame(yesbelt, nobelt)),
e.yesbelt = somma.riga*sum(yesbelt)/n,
e.nobelt = somma.riga*sum(nobelt)/n)
chisq.test(data.frame(yesbelt, nobelt))
names(chisq.test(data.frame(yesbelt, nobelt)))
# compare with the values calculated by R
chisq.test(data.frame(yesbelt, nobelt))$exp
data.frame(yesbelt, nobelt) %>%
mutate(somma.riga = rowSums(data.frame(yesbelt, nobelt)),
e.yesbelt = somma.riga*sum(yesbelt)/n,
e.nobelt = somma.riga*sum(nobelt)/n)
## chi2 - test of homogeneity
die.fair <- sample(1:6, 200, p=c(1,1,1,1,1,1)/6, replace = TRUE)
die.bias <- sample(1:6, 200, p=c(0.5,0.5,1,1,1,2)/6, replace = TRUE)
res.fair <- table(die.fair)
res.bias <- table(die.bias)
rbind(res.fair, res.bias)
chisq.test(rbind(res.fair, res.bias))
names(chisq.test(rbind(res.fair, res.bias)))
freq <- c(53, 22, 49)
probs <- c(5/12, 3/12, 4/12)
chisq.test(freq, p = probs)
r1 <- c(3,1)
r2 <- c(1,0)
chisq.test(data.frame(r1,r2)) -> Xsq
Xsq$observed   # observed counts (same as M)
Xsq$expected
Xsq
Xsq$observed   # observed counts (same as M)
Xsq$expected
Xsq
birds_habitats <- data.frame(
species = c("Ruby-crowed kinglet", "White-crowned sparrow", "Lincoln's sparrow",
"Golgen-crowded sparrow", "Bushtit", "Song sparrow", "Spotted towhee",
"Bewick's wren", "Hermit thrush", "Dard-eyed junco",
"Lesser goldfinch", "Uncommon"),
Remnant = c(677, 408, 270, 300, 198, 150, 137, 106, 119, 34, 57, 457),
Restored = c(198, 260, 187, 89, 91, 50, 32, 48, 24, 39, 15, 125)
)
birds_habitats
chisq.test(data.frame(birds_habitats$Remnant, birds_habitats$Restored))
# ?cars
summary(cars)
cars.lm <- lm(dist ~ speed, data = cars)
names(cars.lm)
coef(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
summary(cars.lm)
-17.58 + 3.93 * (8) # point estimate
cars[5,] # real data
-17.58 + 3.93 * (8) # point estimate
cars[5,] # real data
-17.58 + 3.93 * (8) # point estimate
fitted(cars.lm)
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
plot(dist ~ speed, data = cars, pch = 16)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
carsumry$sigma
summary(cars.lm)
carsumry$sigma
summary(cars.lm)
dim(cars)
summary(cars.lm)
confint(cars.lm)
# new <- data.frame(speed = c(5,6,21))
# predict(cars.lm, newdata = new, interval = "confidence")
# predict(cars.lm, newdata = new, interval = "prediction")
library(HH)
ci.plot(cars.lm)
# or
# library(UsingR)
# simple.lm(cars$speed, cars$dist, show.ci=TRUE)
x = c(18, 23, 25, 35, 65, 54, 34, 56, 72, 19, 23, 42, 18, 39, 37)
y = c(202, 186, 187, 180, 156, 169, 174, 172, 153, 199, 193, 174, 198, 183, 178)
lm(y ~ x) # the basic values of the regression analysis
lm.result = lm(y ~ x)
summary(lm.result)
plot(x,y, xlim=c(0,80), ylim=c(150,240)) # make a plot
abline(coef(lm.result)) #lm(y ~ x)) # plot the regression line
summary(lm.result)
b1 = -0.79773
SE = 0.06996
t = (b1-(-1))/SE # (obs. value - hyp.value)/SE
t
pt(t, 13, lower.tail = FALSE) # FIND THE RIGHT TAIL FOR THIS VALUE OF t AND 15-2 df
# multiply by 2 for a two-sided test
pt(t, 13, lower.tail = FALSE)*2 # < 0.05, REJECT H0: it is unlikely that for this data
t = (b0 - 220)/SE.b0
# COMMENTED LINES - CALCULATIONS BY HAND, YOU CAN SKIP THEM AND USE THE OUTPUT OF THE REGRESSION ANALYSIS
# SE.b0 = s*(sqrt((1/n)+(mean(x)^2/sum((x-mean(x))^2)))) # formula for the standard error of the intercept
SE.b0 = 2.86694
b0 = coef(lm.result)[[1]]
t = (b0 - 220)/SE.b0
t
pt(t, 13, lower.tail = TRUE) # FIND THE LEFT TAIL FOR THIS VALUE OF t AND 15-2 df
growth = c(12, 10, 8, 11, 6, 7, 2, 3.5, 3.5)
tannin = 0:8
lm.result <- lm(growth ~ tannin)
summary(lm.result)
lm.result <- lm(growth ~ tannin)
summary(lm.result)
plot(growth ~ tannin)
abline(coef(lm.result), lwd=2, col="red")
t = (-1.1583 - (-1.5))/0.2236
pt(t, 7, lower.tail = FALSE)
confint(lm.result)
data(cars)
cars.lm <- lm(dist ~ speed, data = cars)
coef(cars.lm)
names(cars.lm)
residuals(cars.lm)
par(mfrow=c(1,3))
hist(residuals(cars.lm))
boxplot(residuals(cars.lm))
qqnorm(residuals(cars.lm))
qqline(residuals(cars.lm))
par(mfrow=c(1,1))
plot(cars.lm)
# install.packages("lmtest")
library(lmtest)
dwtest(cars.lm, alternative = "two.sided")
library(lmtest)
bptest(cars.lm)
