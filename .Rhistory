filter(sex == "F") -> datiF
dati2 %>%
filter(sex == "M") -> datiM
dataset <- datiM
boot.data <- boot(dataset$weight_g,
function(x,i) mean(x[i]),
R=10000)
boot.ci(boot.data,
conf = 0.95)
library(dplyr)
captures <- read.csv("data/captures.csv", sep=";")
captures %>%
filter(age=="A") -> adults
head(adults)
adults %>%
group_by(animal_id, sex) -> grouped
grouped %>%
arrange(animal_id)
grouped %>%
summarise(count=n(), individual.weight = mean(weight_g, na.rm = TRUE)) -> ind.w
ind.w
#?qqplot
qqnorm(ind.w$individual.weight); qqline(ind.w$individual.weight, col="red")
shapiro.test(ind.w$individual.weight)
t.test(ind.w$individual.weight, mu = 30)
length(na.omit(ind.w$individual.weight))
library(dplyr)
## chi2 - goodness of fit test
freq <- c(22, 21, 22, 27, 22, 36)
probs <- rep(1/6, 6)
chisq.test(freq, p = probs)
## chi2 - test of independence
yesbelt <- c(12813, 647, 359, 42)
nobelt <- c(65963, 4000, 2642, 303)
chisq.test(data.frame(yesbelt, nobelt))
names(chisq.test(data.frame(yesbelt, nobelt)))
data.frame(yesbelt, nobelt)
rowSums(data.frame(yesbelt, nobelt))
colSums(data.frame(yesbelt, nobelt))
# for the first cell
78776*13861/sum(data.frame(yesbelt, nobelt))
# for the whole dataframe
n = sum(data.frame(yesbelt, nobelt))
data.frame(yesbelt, nobelt) %>%
mutate(somma.riga = rowSums(data.frame(yesbelt, nobelt)),
e.yesbelt = somma.riga*sum(yesbelt)/n,
e.nobelt = somma.riga*sum(nobelt)/n)
# compare with the values calculated by R
chisq.test(data.frame(yesbelt, nobelt))$exp
chisq.test(data.frame(yesbelt, nobelt))
## chi2 - test of homogeneity
die.fair <- sample(1:6, 200, p=c(1,1,1,1,1,1)/6, replace = TRUE)
die.bias <- sample(1:6, 200, p=c(0.5,0.5,1,1,1,2)/6, replace = TRUE)
res.fair <- table(die.fair)
res.bias <- table(die.bias)
rbind(res.fair, res.bias)
chisq.test(rbind(res.fair, res.bias))
names(chisq.test(rbind(res.fair, res.bias)))
freq <- c(53, 22, 49)
probs <- c(5/12, 3/12, 4/12)
chisq.test(freq, p = probs)
r1 <- c(3,1)
r2 <- c(1,0)
chisq.test(data.frame(r1,r2)) -> Xsq
Xsq$observed   # observed counts (same as M)
Xsq$expected
Xsq
birds_habitats <- data.frame(
species = c("Ruby-crowed kinglet", "White-crowned sparrow", "Lincoln's sparrow",
"Golgen-crowded sparrow", "Bushtit", "Song sparrow", "Spotted towhee",
"Bewick's wren", "Hermit thrush", "Dard-eyed junco",
"Lesser goldfinch", "Uncommon"),
Remnant = c(677, 408, 270, 300, 198, 150, 137, 106, 119, 34, 57, 457),
Restored = c(198, 260, 187, 89, 91, 50, 32, 48, 24, 39, 15, 125)
)
birds_habitats
chisq.test(data.frame(birds_habitats$Remnant, birds_habitats$Restored))
library(dplyr)
captures <- read.csv("data/captures.csv", sep=";")
captures %>%
filter(age=="A") -> adults
head(adults)
adults %>%
group_by(animal_id, sex) -> grouped
grouped %>%
arrange(animal_id)
grouped %>%
summarise(count=n(), individual.weight = mean(weight_g, na.rm = TRUE)) -> ind.w
ind.w
#?qqplot
qqnorm(ind.w$individual.weight); qqline(ind.w$individual.weight, col="red")
shapiro.test(ind.w$individual.weight)
# we use again the summarise dplyr function
ind.w %>%
group_by(sex) %>%
summarise(count=n(), class.weight = mean(individual.weight, na.rm = TRUE))
# We can see the difference in weight that we observe between males and females
w.f <- (subset(ind.w, sex=="F"))$individual.weight
w.m <- (subset(ind.w, sex=="M"))$individual.weight
w.f
w.m
w.f
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.m); qqline(w.m, col="red")
shapiro.test(w.f)
shapiro.test(w.m)
par(mfrow=c(1,2))
qqnorm(w.f); qqline(w.f, col="red")
qqnorm(w.m); qqline(w.m, col="red")
shapiro.test(w.f)
shapiro.test(w.m)
length(w.f)
length(w.m)
x <- rnorm(100,0,1)
curve(df(x, df1=1, df2=1), from=0, to=5, lty=1, ylim=c(0,2))
curve(df(x, df1=2, df2=1), from=0, to=5, lty=2, add=T)
curve(df(x, df1=5, df2=2), from=0, to=5, lty=3, add=T)
curve(df(x, df1=100, df2=1), from=0, to=5, lty=4, add=T)
curve(df(x, df1=100, df2=100), from=0, to=5, lty=5, add=T)
var(w.f, na.rm = T)
var(w.m, na.rm = T)
var(w.f, na.rm = T)
var(w.m, na.rm = T)
var(w.f, na.rm = T)/var(w.m, na.rm = T)
var.test(w.f,w.m)
# ?t.test
t.test(w.f, w.m,
var.equal = TRUE,
paired = FALSE,
alternative = "two.sided") # greater/less
35.7-32.6
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
x <- c(15, 10, 13, 7, 9, 8, 21, 9, 14, 8)
y <- c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var(x)/var(y)
var.test(x,y)
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
#t-test
t.test(x,y,
paired = FALSE,
var.equal = FALSE,
alternative = "two.sided")
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var.test(x,y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
length(x)
# non parametric test
wilcox.test(x,y,
paired = FALSE,
alternative = "two.sided")
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var.test(x,y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
x <- c(15, 10, 13, 7, 9, 8, 21, 9, 14, 8)
y <- c(15, 14, 12, 8, 14, 7, 16, 10, 15, 12)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var(x)/var(y)
var.test(x,y)
#t-test
t.test(x,y,
paired = FALSE,
var.equal = TRUE,
alternative = "two.sided")
# non parametric test
wilcox.test(x,y,
paired = FALSE,
alternative = "two.sided")
x <- c(3, 0, 5, 2, 5, 5, 5, 4, 4, 5)
y <- c(2, 1, 4, 1, 4, 3, 3, 2, 3, 5)
# normality test
# with a qqplot
par(mfrow=c(1,2))
qqnorm(x); qqline(x, col="red")
qqnorm(y); qqline(y, col="red")
# with the Shapiro-Wilk test
shapiro.test(x)
shapiro.test(y)
# homogeneity of variances
var.test(x,y)
# t-test
#t-test
t.test(x,y,
paired = TRUE,
var.equal = TRUE,
alternative = "two.sided")
# non parametric test
wilcox.test(x,y,
paired = TRUE,
alternative = "two.sided")
# Read captures.csv (name it 'captures')
captures <- read.csv("data/captures.csv")
View(captures)
# Read captures.csv (name it 'captures')
captures <- read.csv("data/captures.csv", sep=";")
View(captures)
# Read captures.csv (name it 'captures')
captures <- read.csv("data/captures.csv")
# Read captures.csv (name it 'captures')
captures <- read.csv("data/captures.csv", sep=";")
class(captures)
dim(captures)
names(captures)
# Check the structure of captures
str(captures)
# View a summary of captures
summary(captures)
# View the first 6 rows
head(captures)
head(captures)
# View the first 15 rows
head(captures, n=15)
# View the last 10 rows
tail(captures, n= 10)
# Transform the weight of the animals using the function log
log(captures$weight_g)
# Divide weight by the foot length and save the new variable as wfratio
wfratio <- captures$weight_g/captures$footlength_mm
captures$weight_g/captures$footlength_mm -> wfratio
# add the column wfratio to the captures data frame, creating a new data frame called captures.new
captures.new <- cbind(captures, wfratio) # using R base function `cbind`
captures %>%
mutate(wfratio = weight_g/footlength_mm) -> captures.new
head(captures.new)
# remove the data frame captures.new from the working environment
rm(captures.new)
# remove the data frame captures.new from the working environment
rm(captures.new)
# now add both the log of the weight and the column wfratio to the captures data frame, creating again new data frame called captures.new
captures %>%
mutate(logw = log(weight_g),
wfratio = weight_g/footlength_mm) -> captures.new
head(captures.new)
# select columns by name
captures %>%
select(weight_g, sex, age, footlength_mm)
# select all columns between weight and age
captures %>%
select(weight_g:age)
captures %>%
select(weight_g:footlength_mm)
# select columns from weight_g to footlenght_mm, excluding reproductive status
captures %>%
select(weight_g:footlength_mm) %>%
select(-repr_status)
captures %>%
group_by(sex) %>%
summarise(mean(weight_g, na.rm=TRUE))
captures %>%
group_by(sex) %>%
summarise(media_peso = mean(weight_g, na.rm=TRUE))
# sort the weigth of the animals
sort(captures$weight_g)
captures %>%
arrange(weight_g)
# DO IT ON YOUR OWN
?arrange
captures %>%
group_by(sex)  %>%
arrange(desc(weight_g), .by_group = TRUE)
captures %>%
group_by(sex) %>%
arrange(desc(weight_g))
# order according to weight and then to footlenght
captures %>%
arrange(desc(weight_g), footlength_mm)
## chi2 - goodness of fit test
freq <- c(22, 21, 22, 27, 22, 36)
probs <- rep(1/6, 6)
chisq.test(freq, p = probs)
## chi2 - test of independence
yesbelt <- c(12813, 647, 359, 42)
nobelt <- c(65963, 4000, 2642, 303)
chisq.test(data.frame(yesbelt, nobelt))
chisq.test(data.frame(yesbelt, nobelt))$exp
die.fair <- sample(1:6, 200, p=c(1,1,1,1,1,1)/6, replace = TRUE)
die.bias <- sample(1:6, 200, p=c(0.5,0.5,1,1,1,2)/6, replace = TRUE)
res.fair <- table(die.fair)
res.bias <- table(die.bias)
rbind(res.fair, res.bias)
chisq.test(rbind(res.fair, res.bias))
freq <- c(53, 22, 49)
probs <- c(5/12, 3/12, 4/12)
chisq.test(freq, p = probs)
r1 <- c(3,1)
r2 <- c(1,0)
chisq.test(data.frame(r1,r2)) -> Xsq
Xsq$observed   # observed counts (same as M)
Xsq$expected
Xsq
rbind(res.fair, res.bias)
# ?cars
summary(cars)
cars.lm <- lm(dist ~ speed, data = cars)
names(cars.lm)
coef(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red", lwd=2)
summary(cars.lm)
dim(cars)
-17.58 + 3.93 * (8) # point estimate
cars[5,] # real data
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
fitted(cars.lm)
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
predict(cars.lm, newdata = data.frame(speed = c(6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
predict(cars.lm, newdata = data.frame(speed = c(0,6,8,21)))
plot(dist ~ speed, data = cars, pch = 16)
abline(coef(cars.lm), col="red")
points(cars$speed, fitted(cars.lm), col="red", pch=19)
points(c(6,8,21),
predict(cars.lm, newdata = data.frame(speed = c(6,8,21))),
col="blue", pch=19)
residuals(cars.lm)
# Residual standard error
carsumry <- summary(cars.lm)
summary(cars.lm)
carsumry$sigma
summary(cars.lm)
# new <- data.frame(speed = c(5,6,21))
# predict(cars.lm, newdata = new, interval = "confidence")
# predict(cars.lm, newdata = new, interval = "prediction")
library(HH)
ci.plot(cars.lm)
# or
# library(UsingR)
# simple.lm(cars$speed, cars$dist, show.ci=TRUE)
confint(cars.lm)
# new <- data.frame(speed = c(5,6,21))
# predict(cars.lm, newdata = new, interval = "confidence")
# predict(cars.lm, newdata = new, interval = "prediction")
library(HH)
ci.plot(cars.lm)
# or
# library(UsingR)
# simple.lm(cars$speed, cars$dist, show.ci=TRUE)
lm.result <- lm(growth ~ tannin)
growth = c(12, 10, 8, 11, 6, 7, 2, 3.5, 3.5)
tannin = 0:8
lm.result <- lm(growth ~ tannin)
summary(lm.result)
plot(growth ~ tannin)
abline(coef(lm.result), lwd=2, col="red")
confint(lm.result)
t = (-1.1583 - (-1.5))/0.2236
pt(t, 7, lower.tail = FALSE)
t = (-1.1583 - (-1.5))/0.2236
t
pt(t, 7, lower.tail = FALSE)
length(growth)
pt(t, 7)
pt(t, 7, lower.tail = FALSE)
data(cars)
cars.lm <- lm(dist ~ speed, data = cars)
coef(cars.lm)
names(cars.lm)
residuals(cars.lm)
residuals(cars.lm)
par(mfrow=c(1,3))
hist(residuals(cars.lm))
boxplot(residuals(cars.lm))
qqnorm(residuals(cars.lm))
qqline(residuals(cars.lm))
par(mfrow=c(1,1))
plot(cars.lm)
# install.packages("lmtest")
library(lmtest)
dwtest(cars.lm, alternative = "two.sided")
shapiro.test(residuals(cars.lm))
library(lmtest)
bptest(cars.lm)
data("trees")
head(trees)
hist(trees$Volume)
hist(trees$Volume^2)
hist(trees$Volume)
hist(trees$Volume^2)
library(MASS)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
bctrans
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
seq(0, 0.5, length = 10)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees)
bctrans <- boxcox(Volume ~ Height + Girth, data = trees,
lambda = seq(0, 0.5, length = 10))
which(bctrans$y==max(bctrans$y))
bctrans$x[62]
bctrans
which(bctrans$y==max(bctrans$y))
bctrans$x[62]
hist(trees$Volume)
hist(trees$Volume^0.31)
# load the data
data(trees) # this is a dataframe
class(trees)
# histograms
hist(trees$Girth)
hist(trees$Height)
hist(trees$Volume)
# boxplots
boxplot(trees$Girth)
boxplot(trees$Height)
boxplot(trees$Volume)
# normality test
shapiro.test(trees$Girth)
qqnorm(trees$Girth); qqline(trees$Girth)
data("trees")
mod <- lm(Volume ~ Girth + Height, data=trees)
summary(mod)
# the mean increase in volume when there is a one-unit increase in girth is 4.7
# Volume.tr <- trees$Volume^0.30
# mod.tr <- lm(Volume.tr ~ Girth + Height, data=trees)
# summary(mod.tr)
plot(Volume ~ Girth, data=trees)
mod.q <- lm(Volume ~ Girth + I(Girth^2) +
Height + I(Height^2),
data=trees)
summary(mod.q)
plot(Volume ~ Girth, data=trees)
summary(mod.q)
# alternative code:
mod.q <- lm(Volume ~ poly(Girth, 2, raw=TRUE) + poly(Height, 2, raw=TRUE), data=trees)
summary(mod.q)
plot(Volume ~ Girth, data=trees)
mod.q <- lm(Volume ~ Girth + I(Girth^2) + Height , data=trees)
summary(mod.q)
mod.int <- lm(Volume ~ Girth * Height, data=trees)
summary(mod.int)
mod <- lm(Volume ~ Girth + Height, data=trees)
plot(mod)
plot(trees$Volume ~ trees$Girth)
plot(trees$Volume ~ trees$Height)
mod <- lm(Volume ~ Girth * Height, data=trees)
plot(mod)
plot(trees$Volume ~ trees$Girth)
plot(trees$Volume ~ trees$Height)
library(sjPlot)
# plot_model(mod)
plot_model(mod, type = "eff", terms = "Girth")
plot_model(mod, type = "eff", terms = "Height")
plot_model(mod.int, type = "eff", terms = "Height")
plot_model(mod.int, type = "int", terms = c("Height","Girth")) # # type = "int" automatically selects groups for continuous moderator variables
library(jtools)
effect_plot(mod.int, pred = Girth, interval = TRUE)
plot_model(mod.int, type = "pred", terms = c("Girth", "Height [60,80]"))
# switch moderator
plot_model(mod.int, type = "pred", terms = c("Height", "Girth"))
